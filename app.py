import streamlit as st
from groq import Groq
from gtts import gTTS
import os

# ƒê·∫∑t c·∫•u h√¨nh trang (ph·∫£i l√† l·ªánh ƒë·∫ßu ti√™n)
st.set_page_config(page_title="Chatbot H·ªçc Ng√¥n Ng·ªØ", layout="wide")

# Kh·ªüi t·∫°o Groq API
client = Groq(api_key="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")

# L·ª±a ch·ªçn ng√¥n ng·ªØ
language = st.sidebar.radio("Ch·ªçn ng√¥n ng·ªØ gi·∫£ng d·∫°y:", ["Ti·∫øng Anh", "Ti·∫øng Trung"])

# X√°c ƒë·ªãnh prompt theo ng√¥n ng·ªØ
if language == "Ti·∫øng Anh":
    system_prompt = "B·∫°n l√† gi√°o vi√™n d·∫°y ti·∫øng Anh cho ng∆∞·ªùi Vi·ªát Nam. H√£y tr·∫£ l·ªùi d·ªÖ hi·ªÉu, gi·∫£i th√≠ch r√µ r√†ng, ƒë·∫ßy ƒë·ªß (C·∫•u tr√∫c, c√¥ng th·ª©c), d√πng v√≠ d·ª• c·ª• th·ªÉ, d·ªãch nghƒ©a b·∫±ng ti·∫øng Vi·ªát. N·∫øu c√≥ th·ªÉ, h√£y cung c·∫•p m·∫πo ghi nh·ªõ ho·∫∑c c√°ch s·ª≠ d·ª•ng th·ª±c t·∫ø trong giao ti·∫øp b·∫±ng ti·∫øng Vi·ªát. L∆∞u √Ω t·∫•t c·∫£ ph·∫£i ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát"
    tts_lang = "en"
elif language == "Ti·∫øng Trung":
    system_prompt = "B·∫°n l√† gi√°o vi√™n d·∫°y ti·∫øng Trung cho ng∆∞·ªùi Vi·ªát Nam. H√£y tr·∫£ l·ªùi d·ªÖ hi·ªÉu, gi·∫£i th√≠ch r√µ r√†ng, ƒë·∫ßy ƒë·ªß (C·∫•u tr√∫c, c√¥ng th·ª©c), d√πng v√≠ d·ª• c·ª• th·ªÉ, d·ªãch nghƒ©a b·∫±ng ti·∫øng Vi·ªát. N·∫øu c√≥ th·ªÉ, h√£y cung c·∫•p m·∫πo ghi nh·ªõ ho·∫∑c c√°ch s·ª≠ d·ª•ng th·ª±c t·∫ø trong giao ti·∫øp b·∫±ng ti·∫øng Vi·ªát. L∆∞u √Ω t·∫•t c·∫£ ph·∫£i ƒë∆∞·ª£c tr·∫£ l·ªùi b·∫±ng ti·∫øng Trung"
    tts_lang = "zh"

def ask_groq(query):
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": query}
    ]
    response = client.chat.completions.create(messages=messages, model="llama3-70b-8192")
    return response.choices[0].message.content

# H√†m chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i
def text_to_speech(text):
    tts = gTTS(text, lang=tts_lang)
    tts.save("response.mp3")
    st.audio("response.mp3", format="audio/mp3")

# ===================== GHI √ÇM V√Ä X·ª¨ L√ù GI·ªåNG N√ìI =====================
st.title("üéôÔ∏è Chatbot H·ªçc Ng√¥n Ng·ªØ")
st.write("H√£y n√≥i v√†o micro, chatbot s·∫Ω tr·∫£ l·ªùi b·∫±ng gi·ªçng n√≥i!")

# Ch·∫ø ƒë·ªô h·ªôi tho·∫°i b·∫±ng gi·ªçng n√≥i
def recognize_speech_from_audio(audio):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language="vi-VN")
            return text
        except sr.UnknownValueError:
            return "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i!"
        except sr.RequestError:
            return "L·ªói k·∫øt n·ªëi v·ªõi API nh·∫≠n di·ªán gi·ªçng n√≥i!"

# Nh·∫≠n di·ªán √¢m thanh t·ª´ microphone
webrtc_ctx = webrtc_streamer(
    key="speech-recognition",
    mode=WebRtcMode.SENDRECV,
    audio_receiver_size=1024,
    media_stream_constraints={"video": False, "audio": True},
)

if webrtc_ctx.audio_receiver:
    try:
        audio_frames = webrtc_ctx.audio_receiver.get_frames(timeout=1)
        audio = np.concatenate([frame.to_ndarray() for frame in audio_frames], axis=0)
        
        # L∆∞u √¢m thanh v√†o file t·∫°m
        with open("temp_audio.wav", "wb") as f:
            f.write(audio)

        # Chuy·ªÉn gi·ªçng n√≥i th√†nh vƒÉn b·∫£n
        user_text = recognize_speech_from_audio("temp_audio.wav")
        st.write(f"**üßë‚Äçüéì B·∫°n:** {user_text}")

        # G·ª≠i c√¢u h·ªèi ƒë·∫øn AI
        if user_text:
            with st.spinner("üí≠ ƒêang suy nghƒ©..."):
                answer = ask_groq(user_text)
                st.write(f"**üßë‚Äçüè´ Tr·ª£ l√Ω AI:** {answer}")
                
                # Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i
                text_to_speech(answer)
    except Exception as e:
        st.error(f"L·ªói ghi √¢m: {e}")

